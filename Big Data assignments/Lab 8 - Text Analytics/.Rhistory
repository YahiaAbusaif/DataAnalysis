rm(list=ls())
df = read.csv('movie_reviews.csv', header=TRUE)
cols(df)
colnames(df)
library(tm)
install.packages("tm")
pcorpus <- Corpus(VectorSource(df))
rm(list=ls())
df = read.csv('movie_reviews.csv', header=TRUE)
library(tm)
pcorpus <- Corpus(VectorSource(df))
rm(list=ls())
library(tm)
df = read.csv('movie_reviews.csv', header=TRUE)
inspect(df)
head(df)
str(df)
pcorpus <- Corpus(VectorSource(df$text))
pcorpus = tm_map(pcorpus, tolower)
rm(list=ls())
library(tm)
df = read.csv('movie_reviews.csv', header=TRUE)
str(df)
head(df)
pcorpus = Corpus(VectorSource(df$text))
pcorpus = tm_map(pcorpus, tolower)
pcorpus = tm_map(pcorpus, removePunctuation)
pcorpus = tm_map(pcorpus, removeNumbers)
pcorpus = tm_map(pcorpus, stripWhitespace)
View(pcorpus)
pcorpus = tm_map(pcorpus, removeWords, stopwords("english"))
pdtm <- DocumentTermMatrix(pcorpus)
str(pdtm)
inspect(pdtm)
pdtm <- DocumentTermMatrix(pcorpus[100:110, 15:20)
pdtm <- DocumentTermMatrix(pcorpus[100:110, 15:20])
# 8 documents and 11 terms
inspect(pdtm[100,107, 100:110])
inspect(pdtm)
rm(list=ls())
library(tm)
df = read.csv('movie_reviews.csv', header=TRUE)
str(df)
head(df)
pcorpus = Corpus(VectorSource(df$text))
pcorpus = tm_map(pcorpus, tolower)
pcorpus = tm_map(pcorpus, removePunctuation)
pcorpus = tm_map(pcorpus, removeNumbers)
pcorpus = tm_map(pcorpus, stripWhitespace)
pcorpus = tm_map(pcorpus, removeWords, stopwords("english"))
pdtm <- DocumentTermMatrix(pcorpus)
# 8 documents and 11 terms
inspect(pdtm[100,107, 100:110])
# 8 documents and 11 terms
inspect(pdtm[100:107, 100:110])
# 8 documents and 11 terms
inspect(pdtm[100:107, 56:70])
# 8 documents and 11 terms
inspect(pdtm[100:120, 56:70])
# 8 documents and 11 terms
inspect(pdtm[100:120, 40:70])
# 8 documents and 11 terms
inspect(pdtm[100:120, 10:40])
inspect(pdtm)
3006202016 / (3006202016 + 689184)
str(pdtm)
3006202016 *100/ (3006202016 + 689184)
pdtm <- removeSparseTerms(pdtm, 0.999)
inspect(pdtm)
pfreq <- findFreqTerms(pdtm, 65)
pfreq
# Higher than 65. > 65
pfreq = findFreqTerms(pdtm, lowfreq=66)
findAssocs(pdtm, c("movie", "live"))
findAssocs(pdtm, "movie")
findAssocs(pdtm, c("movie", "live"), c(0.8, 0.8))
findAssocs(pdtm, c("movie", "live"), c(0.1, 0.1))
findAssocs(pdtm, c("movie", "live"), c(0, 0))
findAssocs(pdtm, c("movie", "live"), c(0.1, 0.1))
findAssocs(pdtm, "movie", 0.1)
findAssocs(pdtm, "movie", 0.05)
findAssocs(pdtm, c("movie", "live"), c(0.05, 0.05))
findAssocs(pdtm, c("movie", "live"), c(0.01, 0.01))
pdtm2 <- as.matrix(pdtm)
pdtm2
rm(list=ls())
library(wordcloud)
install.packages("wordcloud")
rm(list=ls())
library(tm)
library(wordcloud)
df = read.csv('movie_reviews.csv', header=TRUE)
str(df)
head(df)
pcorpus = Corpus(VectorSource(df$text))
pcorpus = tm_map(pcorpus, tolower)
pcorpus = tm_map(pcorpus, removePunctuation)
pcorpus = tm_map(pcorpus, removeNumbers)
pcorpus = tm_map(pcorpus, stripWhitespace)
pcorpus = tm_map(pcorpus, removeWords, stopwords("english"))
pdtm = DocumentTermMatrix(pcorpus)
inspect(pdtm)
pdtm = removeSparseTerms(pdtm, 0.999)
# Higher than 65. > 65
pfreq = findFreqTerms(pdtm, lowfreq=66)
pfreq
# Assume find with at least 0.01 correlation
findAssocs(pdtm, c("movie", "live"), c(0.01, 0.01))
inspect(pdtm)
wordFreq = sort(colSums(pdtm2), decreasing=TRUE)
(pdtm)
pdtm2
pdtm2 <- as.matrix(pdtm)
wordFreq = sort(colSums(pdtm2), decreasing=TRUE)
head(wordFreq, n=5)
names(pfrequency)
names(wordFreq)
wordFreq[1]
colSums(pdtm2)
wordcloud(names(wordFreq), wordFreq, max.words=100)
head(wordFreq, n=5)
wordcloud(names(wordFreq), wordFreq, max.words=5)
wordcloud(names(wordFreq), wordFreq, max.words=100)
(names(wordFreq), wordFreq, max.words=100)
wordcloud(names(wordFreq), wordFreq, max.words=100)
wordcloud(names(wordFreq), wordFreq, max.words=100)
wordcloud(names(wordFreq), wordFreq, max.words=100)
rm(list=ls())
library(tm)
library(wordcloud)
df = read.csv('movie_reviews.csv', header=TRUE)
str(df)
head(df)
pcorpus = Corpus(VectorSource(df$text))
pcorpus = tm_map(pcorpus, tolower)
pcorpus = tm_map(pcorpus, removePunctuation)
pcorpus = tm_map(pcorpus, removeNumbers)
pcorpus = tm_map(pcorpus, stripWhitespace)
pcorpus = tm_map(pcorpus, removeWords, stopwords("english"))
pdtm = DocumentTermMatrix(pcorpus)
inspect(pdtm)
pdtm = removeSparseTerms(pdtm, 0.999)
# Higher than 65. > 65
pfreq = findFreqTerms(pdtm, lowfreq=66)
pfreq
# Assume find with at least 0.01 correlation
findAssocs(pdtm, c("movie", "live"), c(0.01, 0.01))
pdtm2 <- as.matrix(pdtm)
wordFreq = sort(colSums(pdtm2), decreasing=TRUE)
head(wordFreq, n=5)
wordcloud(names(wordFreq), wordFreq, max.words=100)
library(tm)
rm(list=ls())
library(tm)
library(wordcloud)
df = read.csv('movie_reviews.csv', header=TRUE)
str(df)
head(df)
pcorpus = Corpus(VectorSource(df$text))
pcorpus = tm_map(pcorpus, tolower)
pcorpus = tm_map(pcorpus, removePunctuation)
pcorpus = tm_map(pcorpus, removeNumbers)
pcorpus = tm_map(pcorpus, stripWhitespace)
pcorpus = tm_map(pcorpus, removeWords, stopwords("english"))
pdtm = DocumentTermMatrix(pcorpus)
inspect(pdtm)
pdtm = removeSparseTerms(pdtm, 0.9999)
# Higher than 65. > 65
pfreq = findFreqTerms(pdtm, lowfreq=66)
pfreq
# Assume find with at least 0.01 correlation
findAssocs(pdtm, c("movie", "live"), c(0.05, 0.05))
pdtm = removeSparseTerms(pdtm, 0.999)
pdtm2 <- as.matrix(pdtm)
wordFreq = sort(colSums(pdtm2), decreasing=TRUE)
head(wordFreq, n=5)
wordcloud(names(wordFreq), wordFreq, max.words=100)
inspect(pdtm)
rm(list=ls())
library(tm)
library(wordcloud)
df = read.csv('movie_reviews.csv', header=TRUE)
str(df)
head(df)
pcorpus = Corpus(VectorSource(df$text))
pcorpus = tm_map(pcorpus, tolower)
pcorpus = tm_map(pcorpus, removePunctuation)
pcorpus = tm_map(pcorpus, removeNumbers)
pcorpus = tm_map(pcorpus, stripWhitespace)
pcorpus = tm_map(pcorpus, removeWords, stopwords("english"))
pdtm = DocumentTermMatrix(pcorpus)
inspect(pdtm)
